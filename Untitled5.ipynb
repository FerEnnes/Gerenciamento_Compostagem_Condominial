{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/lGCbMOxodHr1GDVfIXgS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FerEnnes/Gerenciamento_Compostagem_Condominial/blob/main/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IzcSLRrf1q0y"
      },
      "outputs": [],
      "source": [
        "%pip install -q google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, math, textwrap\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "bjr7zKvS2MXf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = userdata.get(\"GOOGLE_APIKEY_ETIC\")\n",
        "assert api_key, \"No Secrets: crie 'GOOGLE_APIKEY_ETIC' e conceda acesso ao notebook.\"\n",
        "\n",
        "os.environ[\"GOOGLE_APIKEY_ETIC\"] = api_key\n",
        "\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "MODEL = \"gemini-2.5-flash\"\n",
        "generation_config = {\"temperature\": 0.4, \"top_p\": 0.9, \"max_output_tokens\": 3000}\n",
        "\n",
        "print(\"OK: lido dos Secrets e configurado.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM2ZyZtd2h7V",
        "outputId": "9b290d5f-158d-4df9-ee43-12fcdf310eb7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK: lido dos Secrets e configurado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== MODELOS COM generateContent ===\")\n",
        "for model in genai.list_models():\n",
        "    if \"generateContent\" in getattr(model, \"supported_generation_methods\", []):\n",
        "        print(model.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        },
        "id": "_5LLm5M42szZ",
        "outputId": "70aaa6cc-1631-47c7-b2ce-907dc8d2816a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== MODELOS COM generateContent ===\n",
            "models/gemini-2.5-pro-preview-03-25\n",
            "models/gemini-2.5-flash-preview-05-20\n",
            "models/gemini-2.5-flash\n",
            "models/gemini-2.5-flash-lite-preview-06-17\n",
            "models/gemini-2.5-pro-preview-05-06\n",
            "models/gemini-2.5-pro-preview-06-05\n",
            "models/gemini-2.5-pro\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-preview-image-generation\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-2.0-pro-exp\n",
            "models/gemini-2.0-pro-exp-02-05\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/gemini-2.5-flash-preview-tts\n",
            "models/gemini-2.5-pro-preview-tts\n",
            "models/learnlm-2.0-flash-experimental\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/gemma-3n-e4b-it\n",
            "models/gemma-3n-e2b-it\n",
            "models/gemini-flash-latest\n",
            "models/gemini-flash-lite-latest\n",
            "models/gemini-pro-latest\n",
            "models/gemini-2.5-flash-lite\n",
            "models/gemini-2.5-flash-image-preview\n",
            "models/gemini-2.5-flash-image\n",
            "models/gemini-2.5-flash-preview-09-2025\n",
            "models/gemini-2.5-flash-lite-preview-09-2025\n",
            "models/gemini-robotics-er-1.5-preview\n",
            "models/gemini-2.5-computer-use-preview-10-2025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(MODEL, generation_config=generation_config)\n",
        "resp = model.generate_content(\"Diga apenas: OK, funcionando.\")\n",
        "print(resp.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "t-Y97EAB3Gjh",
        "outputId": "1391ad88-6ba6-4550-9f3d-53899571555b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK, funcionando.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sanitize_text(s: str, max_len=300):\n",
        "    s = (s or \"\").strip().replace(\"\\n\", \" \")\n",
        "    return s[:max_len]\n",
        "\n",
        "def validate_numbers(budget, cpr):\n",
        "    try:\n",
        "        budget = float(budget)\n",
        "        cpr = float(cpr)\n",
        "    except:\n",
        "        raise ValueError(\"Orçamento e CPR precisam ser números (ex.: 60 e 3).\")\n",
        "    if budget <= 0 or cpr <= 0:\n",
        "        raise ValueError(\"Orçamento e CPR devem ser > 0.\")\n",
        "    if budget > 1e6 or cpr > 1e5:\n",
        "        raise ValueError(\"Valores muito altos para a aula. Revise.\")\n",
        "    return budget, cpr\n"
      ],
      "metadata": {
        "id": "Fn7dbcSp3Mho"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT_TEMPLATE = \"\"\"Você é uma assistente de marketing didática.\n",
        "Tarefa: gerar 3 IDEIAS de post e 2 LEGENDAS curtas por IDEIA.\n",
        "Regras (guardrails): não prometa resultados; seja clara; sem jargões; ≤ 160 chars por legenda; saída total concisa.\n",
        "Contexto:\n",
        "- Tema/Nicho: {topic}\n",
        "- Público: {audience}\n",
        "- Oferta/Ângulo: {offer}\n",
        "- Tom de voz: {tone}\n",
        "Formato:\n",
        "1) IDEIAS\n",
        "1. ...\n",
        "2. ...\n",
        "3. ...\n",
        "2) LEGENDAS\n",
        "Para IDEIA 1: - ... - ...\n",
        "Para IDEIA 2: - ... - ...\n",
        "Para IDEIA 3: - ... - ...\n",
        "\"\"\"\n",
        "\n",
        "def build_prompt(topic, audience, offer, tone):\n",
        "    return PROMPT_TEMPLATE.format(\n",
        "        topic=sanitize_text(topic),\n",
        "        audience=sanitize_text(audience),\n",
        "        offer=sanitize_text(offer),\n",
        "        tone=sanitize_text(tone),\n",
        "    )"
      ],
      "metadata": {
        "id": "CxjIWG3o3rqo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_response_text(response):\n",
        "    try:\n",
        "        txt = (response.text or \"\").strip()\n",
        "        if txt:\n",
        "            return txt\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        cand = response.candidates[0]\n",
        "        parts = getattr(cand.content, \"parts\", []) or []\n",
        "        texts = [getattr(p, \"text\", \"\") for p in parts if getattr(p, \"text\", \"\")]\n",
        "        if texts:\n",
        "            return \"\\n\".join(texts).strip()\n",
        "        fr = getattr(cand, \"finish_reason\", \"UNKNOWN\")\n",
        "        return f\"[Sem texto na resposta; finish_reason={fr}]\"\n",
        "    except Exception:\n",
        "        return \"[Sem texto e sem candidates]\"\n",
        "\n",
        "def _try_generate(model, prompt):\n",
        "    resp = model.generate_content(prompt)\n",
        "    txt = safe_response_text(resp)\n",
        "    # retry se estourar tokens\n",
        "    if txt.startswith(\"[Sem texto na resposta; finish_reason=2]\"):\n",
        "        short = prompt + \"\\n\\nResponda AINDA mais curto. Priorize listas em 1 linha.\"\n",
        "        resp = model.generate_content(short)\n",
        "        txt = safe_response_text(resp)\n",
        "    return txt\n",
        "\n",
        "def agente_marketing(topic, audience, offer, tone, budget, cpr,\n",
        "                     model=MODEL, gen_config=generation_config):\n",
        "    # guardrails numéricos\n",
        "    budget, cpr = validate_numbers(budget, cpr)\n",
        "    # prompt\n",
        "    prompt = build_prompt(topic, audience, offer, tone)\n",
        "    # geração\n",
        "    model = genai.GenerativeModel(model_name=model, generation_config=gen_config)\n",
        "    texto = _try_generate(model, prompt)\n",
        "    # cálculo controlado (fora do modelo)\n",
        "    estimativa = budget / cpr\n",
        "    # retorno padronizado\n",
        "    return {\n",
        "        \"saida_texto\": texto,\n",
        "        \"estimativa\": {\n",
        "            \"orcamento\": budget,\n",
        "            \"cpr\": cpr,\n",
        "            \"expressao\": f\"{budget}/{cpr}\",\n",
        "            \"resultado_aproximado\": round(estimativa, 2)\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oJibWZvz4F0E"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_nonempty(prompt_text, max_len=300):\n",
        "    while True:\n",
        "        v = input(prompt_text).strip()\n",
        "        if v:\n",
        "            return sanitize_text(v, max_len=max_len)\n",
        "        print(\"⚠️  Campo obrigatório. Tente novamente.\")\n",
        "\n",
        "def get_float_pos(prompt_text, max_val=None):\n",
        "    while True:\n",
        "        v = input(prompt_text).strip().replace(\",\", \".\")\n",
        "        try:\n",
        "            x = float(v)\n",
        "            if x <= 0:\n",
        "                print(\"⚠️  Precisa ser > 0.\")\n",
        "                continue\n",
        "            if max_val and x > max_val:\n",
        "                print(f\"⚠️  Valor muito alto para a aula (>{max_val}). Tente novamente.\")\n",
        "                continue\n",
        "            return x\n",
        "        except:\n",
        "            print(\"⚠️  Digite um número válido (ex.: 60 ou 3).\")\n",
        "\n",
        "print(\"Preencha os campos da campanha (use frases curtas):\\n\")\n",
        "topic    = get_nonempty(\"Tema/Nicho: \")\n",
        "audience = get_nonempty(\"Público: \")\n",
        "offer    = get_nonempty(\"Oferta/Ângulo: \")\n",
        "tone     = get_nonempty(\"Tom de voz: \")\n",
        "budget   = get_float_pos(\"Orçamento (R$): \", max_val=1e6)\n",
        "cpr      = get_float_pos(\"CPR (custo por resultado em R$): \", max_val=1e5)\n",
        "\n",
        "res = agente_marketing(topic, audience, offer, tone, budget, cpr)\n",
        "\n",
        "print(\"\\n=== IDEIAS e LEGENDAS ===\\n\")\n",
        "print(res[\"saida_texto\"])\n",
        "\n",
        "resultado_nome = input(\"\\nResultado medido pelo CPR (ex.: cliques, leads, vendas): \").strip() or \"resultados\"\n",
        "print(\"\\n=== ESTIMATIVA ===\")\n",
        "print(f\"Resultados ≈ orçamento / CPR → {res['estimativa']['expressao']} = {int(res['estimativa']['resultado_aproximado'])} {resultado_nome}\")\n",
        "\n",
        "print(\"\\n(Observação: estimativa é aproximação; não é garantia de performance.)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 724
        },
        "id": "4RzCPlJP4im8",
        "outputId": "4b4e0f71-1088-4fda-c87b-f08f3e0d7efe"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preencha os campos da campanha (use frases curtas):\n",
            "\n",
            "Tema/Nicho: pizza\n",
            "Público: jovem\n",
            "Oferta/Ângulo: frete grátis\n",
            "Tom de voz: urgência\n",
            "Orçamento (R$): 500\n",
            "CPR (custo por resultado em R$): 1\n",
            "\n",
            "=== IDEIAS e LEGENDAS ===\n",
            "\n",
            "Olá! Que legal trabalhar com pizza e frete grátis para a galera jovem! Vamos às ideias e legendas com urgência e clareza:\n",
            "\n",
            "**1) IDEIAS**\n",
            "\n",
            "1.  **Relógio/Contagem Regressiva:** Destaque o frete grátis como uma oferta por tempo limitado. Use um elemento visual de relógio ou \"últimas horas\".\n",
            "2.  **Foco na Fome Imediata:** Mostre a pizza chegando rápido e a alegria de não pagar frete. Enfatize a solução para a fome.\n",
            "3.  **Noite com Amigos:** Incentive a galera a se reunir para pedir pizza, ressaltando o benefício do frete grátis para a confraternização.\n",
            "\n",
            "**2) LEGENDAS**\n",
            "\n",
            "Para IDEIA 1:\n",
            "-   Corre! Frete grátis na sua pizza favorita está acabando. Peça agora e aproveite!\n",
            "-   Última chance de pedir sua pizza sem pagar o frete. Não perca essa! Válido por pouco tempo.\n",
            "\n",
            "Para IDEIA 2:\n",
            "-   Fome bateu? Sua pizza chega rapidinho e o frete é por nossa conta. Peça já!\n",
            "-   Pizza quentinha e frete zero? Sim! Não espere mais, seu pedido está a um clique.\n",
            "\n",
            "Para IDEIA 3:\n",
            "-   Chama a galera! Pizza com frete grátis para a sua noite. Corre para pedir!\n",
            "-   Sua reunião com os amigos merece pizza e frete grátis. Aproveite antes que acabe!\n",
            "\n",
            "Resultado medido pelo CPR (ex.: cliques, leads, vendas): cliques\n",
            "\n",
            "=== ESTIMATIVA ===\n",
            "Resultados ≈ orçamento / CPR → 500.0/1.0 = 500 cliques\n",
            "\n",
            "(Observação: estimativa é aproximação; não é garantia de performance.)\n"
          ]
        }
      ]
    }
  ]
}